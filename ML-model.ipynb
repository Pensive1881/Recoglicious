{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Horray libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"data_dir = tf.keras.utils.get_file('touch_photos', origin=google_path, untar=True)\\ndata_dir = pathlib.Path(data_dir)\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''data_dir = tf.keras.utils.get_file('touch_photos', origin=google_path, untar=True)\n",
    "data_dir = pathlib.Path(data_dir)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "img_height = 180\n",
    "img_width = 180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model building\n",
    "def initialize_model():\n",
    "    num_classes = 2\n",
    "\n",
    "    model = Sequential([\n",
    "      layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
    "      layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "      layers.MaxPooling2D(),\n",
    "      layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "      layers.MaxPooling2D(),\n",
    "      layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "      layers.MaxPooling2D(),\n",
    "      layers.Flatten(),\n",
    "      layers.Dense(128, activation='relu'),\n",
    "      layers.Dense(num_classes),\n",
    "      layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "rescaling (Rescaling)        (None, 180, 180, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 180, 180, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 90, 90, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 90, 90, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 45, 45, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 45, 45, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 22, 22, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 30976)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               3965056   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 258       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 6         \n",
      "=================================================================\n",
      "Total params: 3,988,904\n",
      "Trainable params: 3,988,904\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from csv\n",
    "import pandas as pd\n",
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "\n",
    "# Unpack dataframe to list\n",
    "image = train_df['image'].tolist()\n",
    "label = train_df['label'].tolist()\n",
    "train_list = []\n",
    "train_list.append(image)\n",
    "train_list.append(label)\n",
    "\n",
    "image = test_df['image'].tolist()\n",
    "label = test_df['label'].tolist()\n",
    "test_list = []\n",
    "test_list.append(image)\n",
    "test_list.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Test Split\n",
    "X_train, y_train = train_list\n",
    "X_test, y_test = test_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# horizontal shift image augmentation\n",
    "from numpy import expand_dims\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# load the image\n",
    "img = load_img('_data/_bylabel/_train/0/vlcsnap-2020-12-04-17h06m03s528.png')\n",
    "# convert to numpy array\n",
    "data = img_to_array(img)\n",
    "# expand dimension to one sample\n",
    "samples = expand_dims(data, 0)\n",
    "# create image data augmentation generator\n",
    "datagen = ImageDataGenerator(width_shift_range=[100,800])\n",
    "# prepare iterator\n",
    "it = datagen.flow(samples, batch_size=1)\n",
    "# generate samples and plot\n",
    "for i in range(9):\n",
    "\t# define subplot\n",
    "\tpyplot.subplot(330 + 1 + i)\n",
    "\t# generate batch of images\n",
    "\tbatch = it.next()\n",
    "\t# convert to unsigned integers for viewing\n",
    "\timage = batch[0].astype('uint8')\n",
    "\t# plot raw pixel data\n",
    "\tpyplot.imshow(image)\n",
    "# show the figure\n",
    "pyplot.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[192, 186, 177],\n",
       "        [192, 186, 177],\n",
       "        [193, 187, 178],\n",
       "        ...,\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0]],\n",
       "\n",
       "       [[192, 186, 177],\n",
       "        [192, 186, 177],\n",
       "        [193, 187, 178],\n",
       "        ...,\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0]],\n",
       "\n",
       "       [[191, 185, 176],\n",
       "        [192, 186, 178],\n",
       "        [192, 186, 178],\n",
       "        ...,\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[187, 191, 195],\n",
       "        [193, 197, 201],\n",
       "        [190, 194, 198],\n",
       "        ...,\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0]],\n",
       "\n",
       "       [[187, 191, 195],\n",
       "        [194, 198, 202],\n",
       "        [190, 194, 198],\n",
       "        ...,\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0]],\n",
       "\n",
       "       [[184, 188, 192],\n",
       "        [194, 198, 202],\n",
       "        [190, 194, 198],\n",
       "        ...,\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0]]], dtype=uint8)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = train.take(1)\n",
    "im = list(img)[0][0][0]\n",
    "im = np.array(im)\n",
    "im = im.astype('uint8')\n",
    "from PIL import Image\n",
    "img = Image.fromarray(im, 'RGB')\n",
    "img.show()\n",
    "im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3383 files belonging to 2 classes.\n",
      "Epoch 1/3\n",
      "105/105 [==============================] - 27s 256ms/step - loss: 0.0370 - accuracy: 0.9812\n",
      "Epoch 2/3\n",
      "105/105 [==============================] - 27s 253ms/step - loss: 1.6989e-08 - accuracy: 1.0000\n",
      "Epoch 3/3\n",
      "105/105 [==============================] - 27s 253ms/step - loss: 1.0201e-08 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe5118f2c10>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = initialize_model()\n",
    "\n",
    "random = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    '_data/_random/_train', \n",
    "    batch_size=32, \n",
    "    image_size=(180, 180), \n",
    "    shuffle=True, \n",
    "    validation_split=None,\n",
    ")\n",
    "model.fit(\n",
    "    train,\n",
    "    epochs=3\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3354 files belonging to 2 classes.\n",
      "Found 502 files belonging to 2 classes.\n",
      "Epoch 1/3\n",
      "105/105 [==============================] - 28s 267ms/step - loss: 0.0557 - accuracy: 0.9806 - val_loss: 3.8992e-07 - val_accuracy: 1.0000\n",
      "Epoch 2/3\n",
      "105/105 [==============================] - 28s 266ms/step - loss: 9.5111e-08 - accuracy: 1.0000 - val_loss: 2.7356e-07 - val_accuracy: 1.0000\n",
      "Epoch 3/3\n",
      "105/105 [==============================] - 28s 264ms/step - loss: 6.7175e-08 - accuracy: 1.0000 - val_loss: 2.0517e-07 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# PROTOTYPE for Processing\n",
    "\n",
    "train = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    '_data/_bylabel/_train', \n",
    "    batch_size=32, \n",
    "    image_size=(180, 180), \n",
    "    shuffle=True, \n",
    "    validation_split=None,\n",
    ")\n",
    "\n",
    "test = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    '_data/_bylabel/_test', \n",
    "    batch_size=32, \n",
    "    image_size=(180, 180), \n",
    "    shuffle=False, \n",
    "    validation_split=None,\n",
    ")\n",
    "model.fit(\n",
    "    train,\n",
    "    validation_data=test,\n",
    "    epochs=3\n",
    ")\n",
    "test_preds = model.predict(test)\n",
    "# test_preds.to_csv(ideally with image names, definately with the actual labels)\n",
    "train_preds = model.predict(train)\n",
    "# train_preds.to_csv(ideally with image names, definately with the actual labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_ds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-d17c8cbbcb34>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_ds' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_ds.take(1):\n",
    "  for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "    plt.title(class_names[labels[i]])\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(test).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    '_data/_random', \n",
    "    batch_size=32, \n",
    "    image_size=(180, 180), \n",
    "    shuffle=False, \n",
    "    validation_split=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_GeneratorState',\n",
       " '__abstractmethods__',\n",
       " '__bool__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__nonzero__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__slots__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_abc_impl',\n",
       " '_add_variable_with_custom_getter',\n",
       " '_apply_options',\n",
       " '_as_serialized_graph',\n",
       " '_batch_size',\n",
       " '_checkpoint_dependencies',\n",
       " '_consumers',\n",
       " '_deferred_dependencies',\n",
       " '_drop_remainder',\n",
       " '_flat_shapes',\n",
       " '_flat_structure',\n",
       " '_flat_types',\n",
       " '_functions',\n",
       " '_gather_saveables_for_checkpoint',\n",
       " '_graph',\n",
       " '_graph_attr',\n",
       " '_handle_deferred_dependencies',\n",
       " '_has_captured_ref',\n",
       " '_input_dataset',\n",
       " '_inputs',\n",
       " '_list_extra_dependencies_for_serialization',\n",
       " '_list_functions_for_serialization',\n",
       " '_lookup_dependency',\n",
       " '_map_resources',\n",
       " '_maybe_initialize_trackable',\n",
       " '_name_based_attribute_restore',\n",
       " '_name_based_restores',\n",
       " '_no_dependency',\n",
       " '_object_identifier',\n",
       " '_options_attr',\n",
       " '_preload_simple_restoration',\n",
       " '_restore_from_checkpoint_position',\n",
       " '_self_name_based_restores',\n",
       " '_self_saveable_object_factories',\n",
       " '_self_setattr_tracking',\n",
       " '_self_unconditional_checkpoint_dependencies',\n",
       " '_self_unconditional_deferred_dependencies',\n",
       " '_self_unconditional_dependency_names',\n",
       " '_self_update_uid',\n",
       " '_setattr_tracking',\n",
       " '_shape_invariant_to_type_spec',\n",
       " '_single_restoration_from_checkpoint_position',\n",
       " '_structure',\n",
       " '_tf_api_names',\n",
       " '_tf_api_names_v1',\n",
       " '_trace_variant_creation',\n",
       " '_track_trackable',\n",
       " '_tracking_metadata',\n",
       " '_type_spec',\n",
       " '_unconditional_checkpoint_dependencies',\n",
       " '_unconditional_dependency_names',\n",
       " '_update_uid',\n",
       " '_variant_tensor',\n",
       " '_variant_tensor_attr',\n",
       " '_variant_tracker',\n",
       " 'apply',\n",
       " 'as_numpy_iterator',\n",
       " 'batch',\n",
       " 'cache',\n",
       " 'cardinality',\n",
       " 'class_names',\n",
       " 'concatenate',\n",
       " 'element_spec',\n",
       " 'enumerate',\n",
       " 'filter',\n",
       " 'flat_map',\n",
       " 'from_generator',\n",
       " 'from_tensor_slices',\n",
       " 'from_tensors',\n",
       " 'interleave',\n",
       " 'list_files',\n",
       " 'map',\n",
       " 'options',\n",
       " 'padded_batch',\n",
       " 'prefetch',\n",
       " 'range',\n",
       " 'reduce',\n",
       " 'repeat',\n",
       " 'shard',\n",
       " 'shuffle',\n",
       " 'skip',\n",
       " 'take',\n",
       " 'unbatch',\n",
       " 'window',\n",
       " 'with_options',\n",
       " 'zip']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image classification using TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "img_height = 180\n",
    "img_width = 180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '_data/_bylabel/_train'\n",
    "data_dir = path\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.01,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.01,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_ds.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_ds.take(1):\n",
    "  for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "    plt.title(class_names[labels[i]])\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=10\n",
    "history = model.fit(\n",
    "  train_list,\n",
    "  validation_data=val_ds,\n",
    "  epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_dataset = train\n",
    "\n",
    "val_batches = tf.data.experimental.cardinality(validation_dataset)\n",
    "test_dataset = validation_dataset.take(val_batches // 5)\n",
    "validation_dataset = validation_dataset.skip(val_batches // 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of validation batches: %d' % tf.data.experimental.cardinality(validation_dataset))\n",
    "print('Number of test batches: %d' % tf.data.experimental.cardinality(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "validation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "test_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential([\n",
    "  tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal'),\n",
    "  tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, _ in train_dataset.take(1):\n",
    "  plt.figure(figsize=(10, 10))\n",
    "  first_image = image[0]\n",
    "  for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    augmented_image = data_augmentation(tf.expand_dims(first_image, 0))\n",
    "    plt.imshow(augmented_image[0] / 255)\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rescale = tf.keras.layers.experimental.preprocessing.Rescaling(1./127.5, offset= -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
